# AI-Assisted Refactoring Framework Template

A systematic, safe, and AI-powered approach to refactoring codebases using MCP tools (memory-bank, knowledge-graph, sequential-thinking, docs-provider).

## üéØ Core Principles

- **Safety-First**: Branch isolation, baseline tests, incremental commits
- **AI-Native**: Use LLMs for generation, analysis, and documentation
- **Cognitive Offloading**: AI handles complexity, you handle decisions
- **Knowledge Preservation**: Everything documented automatically
- **Iterative Safety**: Small steps, easy recovery

---

## üìã Pre-Refactor Setup

### 0. Preparation (do once)

| Why | What to do |
|-----|------------|
| Safer refactor | Create a branch: `git checkout -b refactor/[description]` |
| Baseline tests | Run tests: `python cli.py tests run all` (ensure everything is green) |
| Knowledge mapping | Populate knowledge graph with current codebase |
| Auto-documentation | Ensure git hooks update `.universal/memory` automatically |

### Pre-Step Validation Script
```bash
#!/bin/bash
# validate_step.sh
echo "üîç Running pre-step validation..."
python cli.py tests run all && echo "‚úÖ Tests pass" || exit 1
git status --porcelain | wc -l | grep -q "^0$" && echo "‚úÖ Clean working tree" || exit 1
echo "üìä Current metrics:"
# Query knowledge graph for dependency complexity metrics
```

---

## üîÑ Refactoring Steps Template

### Step N: [Description]

**Goal**: [What you want to achieve]

**Impact Analysis**:
```
‚ñ∂ knowledge-graph: "Show all files affected by [change]"
‚ñ∂ memory-bank: "Document design decision for [approach]"
```

**Implementation**:
```
‚ñ∂ sequential-thinking: "Generate code for [specific change] - provide stubs and updated imports"
```

**Validation**:
```bash
# Test the change
python cli.py tests run all
# Quick smoke test
python cli.py system health
```

**Commit**:
```bash
git add .
git commit -m "Step N: [description]"
```

**Mark Complete**:
```
‚ñ∂ sequential-thinking: done N
```

---

## üîß MCP Tools Deep Dive

### Memory Bank (`mcp-memory-bank`)
**Purpose**: Document decisions, store templates, track progress

**Key Operations**:
```bash
# Project management
‚ñ∂ memory-bank: list_projects
‚ñ∂ memory-bank: create_project "refactor-decisions"

# File operations
‚ñ∂ memory-bank: update_file_content project="main" path="adr/step-1-blueprints.md" content="..."
‚ñ∂ memory-bank: get_file_content project="main" path="progress.md"

# Common use cases:
‚ñ∂ memory-bank: "Document ADR: Why Flask blueprints over monolithic routes"
‚ñ∂ memory-bank: "Record rollback plan for Step 3 driver factory"
‚ñ∂ memory-bank: "Store baseline performance metrics before refactor"
‚ñ∂ memory-bank: "Update progress: completed step 2, effects registry working"
```

### Knowledge Graph (`mcp-knowledge-graph`)
**Purpose**: Track code relationships, analyze dependencies, impact analysis

**Key Operations**:
```bash
# Entity management
‚ñ∂ knowledge-graph: create_entities [{"name": "FlaskApp", "entityType": "Component", "observations": ["Main application class"]}]
‚ñ∂ knowledge-graph: create_relations [{"from": "app.py", "to": "effects/__init__.py", "relationType": "imports"}]

# Search and analysis
‚ñ∂ knowledge-graph: search_nodes query="Flask"
‚ñ∂ knowledge-graph: open_nodes names=["app.py", "effects.py"]

# Common refactor queries:
‚ñ∂ knowledge-graph: "Show all files that import app.py"
‚ñ∂ knowledge-graph: "Find circular dependencies in current codebase"
‚ñ∂ knowledge-graph: "List all components that use LED drivers"
‚ñ∂ knowledge-graph: "Compare dependency complexity before/after refactor"
```

### Sequential Thinking (`mcp-sequential-thinking`)
**Purpose**: Plan, generate code, track refactor steps

**Key Operations**:
```bash
# Planning phase
‚ñ∂ sequential-thinking: "Create 6-step plan to refactor app.py into modular blueprints"
‚ñ∂ sequential-thinking: "Analyze impact of splitting effects into plugin registry"

# Implementation phase
‚ñ∂ sequential-thinking: "Generate Flask blueprint code for API routes with proper imports"
‚ñ∂ sequential-thinking: "Create driver factory pattern with environment variable selection"

# Progress tracking
‚ñ∂ sequential-thinking: done 1
‚ñ∂ sequential-thinking: "Review completed steps and plan next iteration"

# Code generation patterns:
‚ñ∂ sequential-thinking: "Generate pytest stubs for [component] with proper fixtures"
‚ñ∂ sequential-thinking: "Create __init__.py files with proper exports for [module]"
‚ñ∂ sequential-thinking: "Generate error handling wrapper for [function]"
```

### Docs Provider (`mcp-docs-provider`)
**Purpose**: Query documentation, generate API docs

**Key Operations**:
```bash
# Documentation queries
‚ñ∂ docs-provider: "How to structure Flask blueprints with WebSocket support?"
‚ñ∂ docs-provider: "Best practices for Python plugin architecture?"

# During refactor:
‚ñ∂ docs-provider: "Generate API documentation for new driver factory"
‚ñ∂ docs-provider: "Update README with new project structure"
```

### MCP Integration Patterns

**1. Cross-Tool Workflows**:
```bash
# Planning ‚Üí Implementation ‚Üí Documentation
‚ñ∂ sequential-thinking: "Plan step 1: split app.py"
‚ñ∂ knowledge-graph: "Show current dependencies of app.py"
‚ñ∂ sequential-thinking: "Generate blueprint code based on dependencies"
‚ñ∂ memory-bank: "Document why we chose this blueprint structure"
```

**2. Validation Chains**:
```bash
# Before each step
‚ñ∂ knowledge-graph: "Verify no circular dependencies"
‚ñ∂ memory-bank: "Record current test coverage baseline"

# After each step  
‚ñ∂ knowledge-graph: "Show what changed in dependency graph"
‚ñ∂ sequential-thinking: "Generate tests for new boundaries"
‚ñ∂ memory-bank: "Update progress and document any issues"
```

**3. Decision Support**:
```bash
# When facing choices
‚ñ∂ docs-provider: "Compare Flask-SocketIO blueprint vs. separate app approaches"
‚ñ∂ memory-bank: "Record pros/cons of each approach"
‚ñ∂ sequential-thinking: "Recommend best option based on our constraints"
‚ñ∂ knowledge-graph: "Show impact of chosen approach on existing code"
```

---

## üõ† Common Refactoring Patterns

### 1. Split Monolithic File

**Example**: Breaking up `cli.py` into modules

```
‚ñ∂ sequential-thinking: "Generate modular CLI structure with separate command modules and rewrite cli.py with command registration"
```

**Target Structure**:
```
your-repo/
‚îú‚îÄ commands/       ‚Üê CLI command modules
‚îÇ  ‚îú‚îÄ __init__.py
‚îÇ  ‚îú‚îÄ generate.py
‚îÇ  ‚îú‚îÄ config.py
‚îÇ  ‚îî‚îÄ system.py
‚îú‚îÄ cli.py          ‚Üê now just command registration and main entry point
```

### 2. Driver/Factory Pattern

**Goal**: Abstract hardware vs. mock implementations

```
‚ñ∂ memory-bank: "Add design note describing driver_factory pattern (env var API_DRIVER)"
‚ñ∂ sequential-thinking: "Generate code for driver_factory.py and update imports"
```

**Target Structure**:
```
drivers/
‚îú‚îÄ __init__.py
‚îú‚îÄ forge_api.py
‚îú‚îÄ mock_api.py
‚îî‚îÄ factory.py
```

### 3. Plugin/Registry System

**Goal**: Extensible effect system

```python
# Pattern:
EFFECTS = {}
def register(name):
    def wrapper(cls):
        EFFECTS[name] = cls
        return cls
    return wrapper

@register("fade")
class Fade(Effect):
    ...
```

```
‚ñ∂ sequential-thinking: "Refactor effects/ with register() decorator ‚Äì generate updated code stubs"
```

### 4. Configuration/Validation Layer

**Goal**: JSON schema validation for configuration files

```
‚ñ∂ memory-bank: "Document JSON schema for configuration files ‚Äì fields, types, ranges"
‚ñ∂ sequential-thinking: "Generate config_validation.py with load_config(), save_config(), and validate(schema)"
```

### 5. Test Infrastructure

**Focus**: Test new boundaries you just carved out

```
tests/
‚îú‚îÄ test_effects.py   # registry returns correct class
‚îú‚îÄ test_driver.py    # factory selects mock vs hardware
‚îú‚îÄ test_config.py    # invalid JSON raises ValidationError
```

```
‚ñ∂ sequential-thinking: "Generate pytest stubs for effects, driver factory, config validation"
```

### 6. Documentation & Naming Sweep

**Goal**: Consistent naming and comprehensive docs

```
‚ñ∂ memory-bank: "Add note: adopted snake_case for modules, CamelCase for classes"
```

Use Cursor's multi-file rename: `Shift ‚åò R` (Mac) or `Shift Alt R` (Win)

---

## üìä Enhanced Process Features

### A. Architecture Decision Records (ADRs)
```
‚ñ∂ memory-bank: "Record ADR: Why we chose Flask blueprints over FastAPI routers"
‚ñ∂ memory-bank: "Document rollback procedure for Step 3 if plugin registry breaks"
```

### B. Dependency Impact Analysis
```
‚ñ∂ knowledge-graph: "Compare dependency complexity before/after refactor"
‚ñ∂ knowledge-graph: "Verify no circular dependencies after Step 2"
‚ñ∂ knowledge-graph: "Show import chain depth before/after"
```

### C. Performance Monitoring
```
‚ñ∂ memory-bank: "Baseline performance metrics before refactor"
‚ñ∂ memory-bank: "Compare performance impact after refactor"
```

### D. Test-Driven Validation
```bash
# Before each step:
python cli.py tests run all --coverage
# Ensure coverage doesn't drop

# After each step:
‚ñ∂ sequential-thinking: "Generate integration test for [new component]"
```

---

## üéØ Finishing the Refactor

### 7. Final Validation

1. **Full System Test**:
   ```bash
   # Run the full app locally
   python cli.py web start
   # Test all functionality
   ```

2. **Integration Verification**:
   ```
   ‚ñ∂ knowledge-graph: "Generate final dependency map"
   ‚ñ∂ memory-bank: "Document all changes made during refactor"
   ```

3. **Documentation Update**:
   ```
   ‚ñ∂ docs-provider: "Regenerate docs and update CHANGELOG for v[X.Y.Z]"
   ```

4. **Create PR**:
   - Include knowledge graph dependency comparison
   - Reference memory bank design decisions
   - Paste auto-generated documentation

5. **Cleanup**:
   ```bash
   git push origin refactor/[description]
   # Create PR, merge, delete branch
   # Memory bank & checklist remain as historical record
   ```

---

## üìù Post-Refactor Review

### Questions to Ask:
1. **Complexity**: Did we reduce cognitive load?
2. **Testability**: Are new boundaries easier to test?
3. **Maintainability**: Will this be easier to extend?
4. **Performance**: Any regression in speed/memory?
5. **Documentation**: Is the new architecture clear?

### Metrics to Track:
```
‚ñ∂ knowledge-graph: "Count total dependencies before/after"
‚ñ∂ knowledge-graph: "Show coupling metrics improvement"
‚ñ∂ memory-bank: "List all design decisions made"
```

---

## üöÄ Usage Examples

### Starting a Refactor:
```bash
git checkout -b refactor/modular-split
‚ñ∂ sequential-thinking: "Create 6-step plan to refactor monolithic cli.py into modular command structure"
```

### Each Step:
```
‚ñ∂ sequential-thinking: "Generate code for step 1 ‚Äì create command modules and rewrite cli.py with command registration"
# Accept/tweak generated code
git add . && git commit -m "Step 1: split cli.py into command modules"
‚ñ∂ sequential-thinking: done 1
```

### Verification:
```
‚ñ∂ knowledge-graph: "Show what changed in dependency graph"
‚ñ∂ memory-bank: "Document why we chose this approach"
```

---

## üéÅ Benefits of This Framework

1. **üß† Cognitive Offloading**: AI handles complexity, you handle decisions
2. **üìö Knowledge Preservation**: Everything documented automatically  
3. **üîÑ Iterative Safety**: Small steps, easy recovery
4. **üéØ Goal-Oriented**: Each step has clear deliverable
5. **ü§ñ AI-Native**: Uses LLMs for their strengths (generation, analysis)
6. **üìä Data-Driven**: Metrics guide decisions
7. **üîç Transparent**: Full audit trail of changes and reasoning

---

## üìã Checklist Template

- [ ] Branch created
- [ ] Baseline tests pass
- [ ] Knowledge graph populated
- [ ] Step 1: [Description]
- [ ] Step 2: [Description]
- [ ] Step 3: [Description]
- [ ] Step 4: [Description]
- [ ] Step 5: [Description]
- [ ] Step 6: [Description]
- [ ] Final validation
- [ ] Documentation updated
- [ ] PR created and merged

---

**This framework is production-ready and can be adapted for any refactoring project. The key is consistent use of AI tools for planning, generation, and documentation while maintaining engineering best practices.** 